{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMA Final Project - Rap Language Model\n",
    "\n",
    "This notebook: language modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, re\n",
    "from nltk import word_tokenize, regexp_tokenize\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "    artists = []\n",
    "    seqs = []\n",
    "    targets = []\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            artists.append(int(line[0]))\n",
    "            seqs.append(line[1].split())\n",
    "            targets.append(line[2])\n",
    "           \n",
    "    return (np.array(artists), seqs, targets)\n",
    "\n",
    "def read_map(file):\n",
    "    a2b = {}\n",
    "    with open(file, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('\\t')\n",
    "            a2b[line[0]] = line[1]\n",
    "    return a2b\n",
    "    \n",
    "# train = read_data(os.path.join(_dir, 'train.tsv'))\n",
    "# val = read_data(os.path.join(_dir, 'val.tsv'))\n",
    "# test = read_data(os.path.join(_dir, 'test.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dir = 'data/rap_max100_10'\n",
    "#\n",
    "# a_{train|val|test} = artist ids\n",
    "# x_{train|val|test} = token sequences of length seq_length\n",
    "# y_{train|val|test} = target tokens for each sequence\n",
    "#\n",
    "a_train, x_train, y_train = read_data(os.path.join(_dir, 'train.tsv'))\n",
    "a_val, x_val, y_val = read_data(os.path.join(_dir, 'val.tsv'))\n",
    "a_test, x_test, y_test = read_data(os.path.join(_dir, 'test.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist2id = read_map(os.path.join(_dir, 'artist2id.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30098"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap_vocab = Counter([t for sample in x_train for t in sample])\n",
    "len(rap_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of tokens - \n",
    "# want to make sure that <BR> and <UNK> are not dominating\n",
    "ys = Counter()\n",
    "n = len(y_train)\n",
    "for word in y_train:\n",
    "    ys[word] += 100./n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pretrained Glove embeddings\n",
    "\n",
    "***Selecting Vocabulary Size***\n",
    "\n",
    "The rap corpus contains 55538 unique tokens (printed out in cell above). Here I load in pretrained Glove embeddings and check how much coveragewe get when using 100k, 200k,... tokens. Corpus coverage takes into account token frequency in our corpus.\n",
    "\n",
    "| vocab size | token coverage   | corpus coverage |\n",
    "|------|------|------|\n",
    "| 50k  | 45.43% | 95.46% | \n",
    "| 100k | 56.51% | 96.67% | \n",
    "| 200k | 63.60% | 98.05%|\n",
    "| 300k | % | %|\n",
    "| 400k | % | %|\n",
    "\n",
    "Looks like using all 400k tokens does not give us a huge advantage in terms of corpus coverage (87% vs 85%). Limiting the vocabulary size will make the model a little bit easier to train.  Lets start with vocab size of **50k**.\n",
    "\n",
    "Examining tokens for which we don't have coverage - most are strange spellings or words in other languages. These will be replaced with <UNK> token during model training.\n",
    "    \n",
    "**Unknown tokens**: {'irreputable',\n",
    " '77777777',\n",
    " 'heini',\n",
    " 'wallabees',\n",
    " 'motherfuckerss',\n",
    " 'jip',\n",
    " 'gyrate',\n",
    " 'lights…',\n",
    " 'pigsties',\n",
    " 'hassans',\n",
    " 'muthaphukka',\n",
    " 'jiggy',\n",
    " \"'months\",\n",
    " 'allergenic',\n",
    " 'девки',\n",
    " 'nestlé',\n",
    " 'westbank',\n",
    " 'boggles',\n",
    " 'tieing',...}\n",
    " \n",
    " **Most frequent unknown tokens**: ('nigga', 21525),\n",
    " ('niggas', 18183),\n",
    " (\"'all\", 6122),\n",
    " ('!)', 4568),\n",
    " (\"',\", 4442),\n",
    " ('bitches', 4082),\n",
    " ('hoes', 3003),\n",
    " (\"'ma\", 2211),\n",
    " ('pussy', 2117),\n",
    " (\"'bout\", 2092),\n",
    " ('..', 1893),\n",
    " ('motherfucker', 1848),\n",
    " ('?)', 1811),\n",
    " ('tryna', 1776),\n",
    " ('ooh', 1727),\n",
    " (\"'mma\", 1501),\n",
    " ('motherfuckers', 1373)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(filename, max_vocab_size, emb_dim):\n",
    "\n",
    "    vocab={}\n",
    "    embeddings=[]\n",
    "    with open(filename) as file:\n",
    "        \n",
    "        cols=file.readline().split(\" \")\n",
    "        num_words=int(cols[0])\n",
    "        size=int(cols[1])\n",
    "        embeddings.append(np.zeros(size))  # 0 = 0 padding if needed\n",
    "        embeddings.append(np.random.uniform(-1,1,emb_dim))  # 1 = UNK\n",
    "        embeddings.append(np.random.uniform(-1,1,emb_dim))  # 1 = <BR>\n",
    "        vocab[\"<PAD>\"]=0\n",
    "        vocab[\"<UNK>\"]=1\n",
    "        vocab[\"<BR>\"]=2\n",
    "        \n",
    "        for idx,line in enumerate(file):\n",
    "\n",
    "            if idx+3 >= max_vocab_size:\n",
    "                break\n",
    "\n",
    "            cols=line.rstrip().split(\" \")\n",
    "            val=np.array(cols[1:])\n",
    "            word=cols[0]\n",
    "            \n",
    "            embeddings.append(val)\n",
    "            vocab[word]=idx+3\n",
    "\n",
    "    return np.array(embeddings), vocab, size\n",
    "\n",
    "def tok_to_id(tok, vocab):\n",
    "    if tok in vocab:\n",
    "        return vocab[tok]\n",
    "    \n",
    "    if tok[-1]=='n' and tok+'g' in vocab:\n",
    "        # 'growin' -> 'growing'\n",
    "        # 'obeyin' -> 'obeying'\n",
    "        return vocab[tok+'g']\n",
    "    \n",
    "    return vocab['<UNK>']\n",
    "    \n",
    "def check_glove_coverage(vocab, tokens, vocab_map={}):  \n",
    "    in_vocab = set()\n",
    "    out_vocab = set()\n",
    "    all_vocab = set()\n",
    "    \n",
    "    in_count = 0\n",
    "    out_count = 0\n",
    "    all_count = 0\n",
    "    \n",
    "    out_counter = Counter()\n",
    "    for tok in tokens:\n",
    "        \n",
    "        if tok in vocab_map:\n",
    "            tok = vocab_map[tok]\n",
    "        \n",
    "        if tok in vocab or tok == '<BR>':\n",
    "            in_vocab.add(tok)\n",
    "            in_count += tokens[tok]            \n",
    "        elif tok[-1]=='n' and tok+'g' in vocab:\n",
    "            # 'growin' -> 'growing'\n",
    "            # 'obeyin' -> 'obeying'\n",
    "            in_vocab.add(tok)\n",
    "            in_count += tokens[tok]\n",
    "        else:\n",
    "            out_counter[tok] += tokens[tok]\n",
    "            out_vocab.add(tok)\n",
    "            out_count += tokens[tok]\n",
    "        all_vocab.add(tok)\n",
    "        all_count += tokens[tok]\n",
    "        \n",
    "    print(\"{:.2%} of unique tokens covered\".format(len(in_vocab)/len(all_vocab)))\n",
    "    print(\"{:.2%} of corpus covered\".format(in_count/all_count))\n",
    "    \n",
    "    return in_vocab, out_vocab, all_vocab, out_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.78% of unique tokens covered\n",
      "95.72% of corpus covered\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50000\n",
    "vocab_dim = 100\n",
    "emb, tok2id, size = load_embeddings('data/glove/glove.6B/glove.6B.100d.w2v', vocab_size, vocab_dim)\n",
    "in_, out_, all_, out_counter = check_glove_coverage(tok2id, rap_vocab, vocab_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.78% of unique tokens covered\n",
      "95.72% of corpus covered\n"
     ]
    }
   ],
   "source": [
    "vocab_map = {\n",
    "    \"'bout\": 'about',\n",
    "    \"'ma\": \"am\",\n",
    "    \"'mma\": \"am\",\n",
    "    \"uhh\": \"uh\",\n",
    "    \"'all\": \"all\"\n",
    "}\n",
    "in_, out_, all_, out_counter = check_glove_coverage(tok2id, rap_vocab, vocab_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.06% of unique tokens covered\n",
      "95.90% of corpus covered\n"
     ]
    }
   ],
   "source": [
    "in_, out_, all_, out_counter = check_glove_coverage(tok2id, rap_vocab, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11720 30098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "882"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOMAIN SPECIFIC VOABULARY\n",
    "print(len(out_), len(all_))\n",
    "len([o for o in out_counter if out_counter[o]>50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nigga', 46314),\n",
       " ('niggas', 39779),\n",
       " (\"'all\", 13262),\n",
       " ('bitches', 7929),\n",
       " ('hoes', 5849),\n",
       " (\"'ma\", 5296),\n",
       " (\"'bout\", 4778),\n",
       " ('motherfucker', 4221),\n",
       " ('pussy', 4111),\n",
       " ('ooh', 4034),\n",
       " ('tryna', 3719),\n",
       " (\"'mma\", 3298),\n",
       " (\"'mon\", 2989),\n",
       " ('uhh', 2853),\n",
       " ('motherfuckers', 2786),\n",
       " ('homie', 2599),\n",
       " ('motherfuckin', 2358),\n",
       " ('fucked', 2333),\n",
       " ('cuz', 2241),\n",
       " ('woah', 2177),\n",
       " ('biggie', 1980),\n",
       " ('holla', 1863),\n",
       " ('bullshit', 1828),\n",
       " ('outta', 1770),\n",
       " ('yea', 1675),\n",
       " ('thang', 1614),\n",
       " ('ayo', 1502),\n",
       " ('gat', 1362),\n",
       " ('ayy', 1341),\n",
       " ('homies', 1161),\n",
       " ('whatchu', 1110),\n",
       " ('motherfucking', 1103),\n",
       " ('tw', 1103),\n",
       " ('ballin', 1080),\n",
       " ('aight', 1041),\n",
       " ('busta', 1039),\n",
       " ('haters', 1031),\n",
       " ('jockin', 1021),\n",
       " ('pimpin', 968),\n",
       " ('jiggy', 967),\n",
       " ('rakim', 936),\n",
       " (\"'fore\", 924),\n",
       " ('twerk', 903),\n",
       " (\"'round\", 900),\n",
       " ('luda', 884),\n",
       " ('shawty', 884),\n",
       " ('haha', 829),\n",
       " ('tical', 808),\n",
       " ('dawg', 793),\n",
       " ('izz', 774),\n",
       " ('hmm', 755),\n",
       " ('gots', 745),\n",
       " ('goddamn', 737),\n",
       " ('thats', 731),\n",
       " ('smalls', 724),\n",
       " ('ohh', 721),\n",
       " ('weezy', 717),\n",
       " ('finna', 704),\n",
       " ('ahh', 677),\n",
       " ('yup', 676),\n",
       " ('trill', 676),\n",
       " ('hov', 672),\n",
       " ('fiend', 664),\n",
       " (\"'cha\", 662),\n",
       " ('dudes', 626),\n",
       " ('nuttin', 603),\n",
       " ('swerve', 592),\n",
       " ('wack', 578),\n",
       " ('flipmode', 573),\n",
       " ('snitches', 570),\n",
       " ('killa', 561),\n",
       " ('gats', 554),\n",
       " ('2pac', 553),\n",
       " ('blunts', 548),\n",
       " ('piss', 542),\n",
       " ('broads', 515),\n",
       " ('illest', 511),\n",
       " ('naw', 502),\n",
       " ('fam', 500),\n",
       " ('poppa', 499),\n",
       " ('everytime', 498),\n",
       " ('yall', 485),\n",
       " ('hater', 481),\n",
       " ('floss', 472),\n",
       " ('thangs', 466),\n",
       " ('aiyyo', 460),\n",
       " ('icky', 459),\n",
       " ('muthafuckin', 454),\n",
       " ('witcha', 449),\n",
       " ('henny', 448),\n",
       " ('ugh', 440),\n",
       " ('glocks', 438),\n",
       " ('gobble', 426),\n",
       " ('ryders', 424),\n",
       " ('fiends', 421),\n",
       " ('mami', 416),\n",
       " ('peeps', 408),\n",
       " ('realest', 407),\n",
       " ('whats', 403),\n",
       " ('ow', 396)]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_counter.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "domain_words = [x[0] for x in out_counter.most_common(1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = len(tok2id)\n",
    "for word in domain_words:\n",
    "    tok2id[word] = idx\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tok2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_id = np.array([[tok_to_id(t, tok2id) for t in seq] for seq in x_train])\n",
    "y_train_id = np.array([tok_to_id(t, tok2id) for t in y_train])\n",
    "x_val_id = np.array([[tok_to_id(t, tok2id) for t in seq] for seq in x_val])\n",
    "y_val_id = np.array([tok_to_id(t, tok2id) for t in y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3955008, 10) (3955008,) (494376, 10) (494376,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_id.shape, y_train_id.shape, x_val_id.shape, y_val_id.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from keras.layers import Dense, Input, Embedding, Lambda, Layer, Multiply, \\\n",
    "Dropout, Dot, Bidirectional, LSTM, concatenate, Flatten\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, Callback\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable annoying tensorflow \"deprecated\" messages\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "top10_acc = functools.partial(keras.metrics.sparse_top_k_categorical_accuracy, k=10)\n",
    "top10_acc.__name__ = 'top10_acc'\n",
    "top5_acc = functools.partial(keras.metrics.sparse_top_k_categorical_accuracy, k=5)\n",
    "top5_acc.__name__ = 'top5_acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "source_emb (Embedding)          (None, 1, 50)        1000        input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "word_emb (Embedding)            (None, None, 100)    5100000     input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 50)           0           source_emb[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 25)           12600       word_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 75)           0           flatten_6[0][0]                  \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 25)           1900        concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "predict (Dense)                 (None, 51000)        1326000     dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 6,441,500\n",
      "Trainable params: 6,441,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class AttentionLayerMasking(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(AttentionLayerMasking, self).__init__(**kwargs)\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_embedding_dim=input_shape[-1]\n",
    "        \n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                            shape=(input_embedding_dim,1),\n",
    "                            initializer='uniform',\n",
    "                            trainable=True)\n",
    "        super(AttentionLayerMasking, self).build(input_shape)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        \n",
    "        # dot product \n",
    "        x=K.dot(x, self.kernel)\n",
    "        # exponentiate\n",
    "        x=K.exp(x)\n",
    "        \n",
    "        # zero out elements that are masked\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask, axis=-1)\n",
    "            x = x * mask\n",
    "        \n",
    "        # normalize by sum\n",
    "        x /= K.sum(x, axis=1, keepdims=True)\n",
    "        x=K.squeeze(x, axis=2)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[1])\n",
    "    \n",
    "def get_model(embeddings, lstm_size=25, dropout_rate=0.25):\n",
    "\n",
    "    vocab_size, word_embedding_dim=embeddings.shape \n",
    "    word_sequence_input = Input(shape=(None,), dtype='int32')\n",
    "    \n",
    "    word_embedding_layer = Embedding(vocab_size,\n",
    "                                    word_embedding_dim,\n",
    "                                    weights=[embeddings],\n",
    "                                    trainable=False)\n",
    "\n",
    "    \n",
    "    embedded_sequences = word_embedding_layer(word_sequence_input)\n",
    "    bilstm_output = Bidirectional(LSTM(lstm_size, \n",
    "                                       return_sequences=True, \n",
    "                                       activation='tanh', \n",
    "                                       dropout=dropout_rate), merge_mode='concat')(embedded_sequences)\n",
    "\n",
    "    # first let's transform each word embedding into a new vector to use for measuring its importance\n",
    "    attention_key_dim=300\n",
    "    attention_input=Dense(attention_key_dim, activation='tanh')(bilstm_output)\n",
    "\n",
    "    # next we'll pass those transformed inputs through an attention layer, getting back a normalized\n",
    "    # attention value a_i for each token i; \\forall i, 0 <= a_i <= 1; for a document with N words, \n",
    "    # \\sum_{i=0}^N a_i = 1\n",
    "    \n",
    "    attention_output = AttentionLayerMasking(word_embedding_dim, name=\"attention\")(attention_input)\n",
    "    \n",
    "    # now let's multiply those attention weights by original inputs to get a weighted average over them\n",
    "    document_representation = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=1), name='dot')([attention_output,bilstm_output])\n",
    "\n",
    "    x=Dense(vocab_size, activation=\"softmax\")(document_representation)\n",
    "\n",
    "    model = Model(inputs=word_sequence_input, outputs=x)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_simple_lstm(embeddings, lstm_size=25, dropout_rate=0.1):\n",
    "    vocab_size, word_embedding_dim=embeddings.shape \n",
    "    word_sequence_input = Input(shape=(None,), dtype='int32')\n",
    "    \n",
    "    word_embedding_layer = Embedding(vocab_size,\n",
    "                                    word_embedding_dim,\n",
    "                                    weights=[embeddings],\n",
    "                                    trainable=False)\n",
    "\n",
    "    \n",
    "    # input - embeddings\n",
    "    embedded_sequences = word_embedding_layer(word_sequence_input)\n",
    "    # lstm layer\n",
    "    lstm_output = LSTM(lstm_size, \n",
    "                       return_sequences=False, \n",
    "                       activation='tanh', \n",
    "                       dropout=dropout_rate)(embedded_sequences)\n",
    "    # + dense layer\n",
    "#     dense_output = Dense(128, activation='tanh')(lstm_output)\n",
    "    # + droupout\n",
    "#     seq_representation = Dropout(dropout_rate)(dense_output)\n",
    "    # final output - softmax over all vocabulary\n",
    "    x=Dense(vocab_size, activation=\"softmax\")(lstm_output)\n",
    "    \n",
    "    model = Model(inputs=word_sequence_input, outputs=x)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['sparse_categorical_accuracy', top5_acc, top10_acc, perplexity])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_lstm_source(embeddings, lstm_size=25, dropout_rate=0.1, source_n=10, source_dim=50, dense_dim=25):\n",
    "    \n",
    "    # word embeddings\n",
    "    vocab_size, word_embedding_dim=embeddings.shape\n",
    "    word_embedding_layer = Embedding(vocab_size,\n",
    "                                    word_embedding_dim,\n",
    "                                    weights=[embeddings],\n",
    "                                    trainable=True,\n",
    "                                    name='word_emb')\n",
    "    # source embeddings\n",
    "    source_embedding_layer = Embedding(source_n, \n",
    "                                       source_dim, \n",
    "                                       input_length=1, \n",
    "                                       trainable=True,\n",
    "                                       name='source_emb')\n",
    "    \n",
    "    # inputs\n",
    "    word_sequence_input = Input(shape=(None,), dtype='int32')\n",
    "    source_input = Input(shape=(1,), dtype='int32')\n",
    "    \n",
    "    # build model\n",
    "    embedded_sequences = word_embedding_layer(word_sequence_input) # (batch_size x seq_length x embedding_dim)\n",
    "    embedded_sources = Flatten()(source_embedding_layer(source_input)) # (batch_size x source_dim)\n",
    "    \n",
    "    # pass sequences through lstm\n",
    "    lstm_output = LSTM(lstm_size, \n",
    "                       return_sequences=False, \n",
    "                       activation='tanh', \n",
    "                       dropout=dropout_rate,\n",
    "                       name='lstm')(embedded_sequences)\n",
    "    \n",
    "    # concat with source embeddings\n",
    "    combined = concatenate([embedded_sources, lstm_output])\n",
    "    \n",
    "    # Dense layer over concat -> predict\n",
    "    combined = Dense(dense_dim, activation=\"tanh\", name='dense')(combined)\n",
    "    x=Dense(vocab_size, activation=\"softmax\", name='predict')(combined)\n",
    "    \n",
    "    # compile model\n",
    "    model = Model(inputs=[word_sequence_input, source_input], outputs=x)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam', \n",
    "                  metrics=['sparse_categorical_accuracy', top5_acc, top10_acc])\n",
    "    \n",
    "    return model\n",
    "\n",
    "lstm_source_model = get_lstm_source(emb, lstm_size=25, source_n=len(artist2id))\n",
    "print(lstm_source_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 256 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "256/256 [==============================] - 14s 54ms/step - loss: 10.8392 - sparse_categorical_accuracy: 0.0000e+00 - top5_acc: 0.0000e+00 - top10_acc: 0.0000e+00 - val_loss: 10.8376 - val_sparse_categorical_accuracy: 0.0000e+00 - val_top5_acc: 0.0000e+00 - val_top10_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 10.8344 - sparse_categorical_accuracy: 0.0000e+00 - top5_acc: 0.0039 - top10_acc: 0.0039 - val_loss: 10.8340 - val_sparse_categorical_accuracy: 0.0000e+00 - val_top5_acc: 0.0078 - val_top10_acc: 0.0234\n",
      "Epoch 3/10\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 10.8282 - sparse_categorical_accuracy: 0.0078 - top5_acc: 0.0430 - top10_acc: 0.0664 - val_loss: 10.8298 - val_sparse_categorical_accuracy: 0.0039 - val_top5_acc: 0.0273 - val_top10_acc: 0.0664\n",
      "Epoch 4/10\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 10.8206 - sparse_categorical_accuracy: 0.0117 - top5_acc: 0.0938 - top10_acc: 0.1406 - val_loss: 10.8248 - val_sparse_categorical_accuracy: 0.0039 - val_top5_acc: 0.0312 - val_top10_acc: 0.0781\n",
      "Epoch 5/10\n",
      "256/256 [==============================] - 4s 17ms/step - loss: 10.8124 - sparse_categorical_accuracy: 0.0078 - top5_acc: 0.0859 - top10_acc: 0.1641 - val_loss: 10.8189 - val_sparse_categorical_accuracy: 0.0195 - val_top5_acc: 0.0508 - val_top10_acc: 0.0820\n",
      "Epoch 6/10\n",
      "256/256 [==============================] - 5s 20ms/step - loss: 10.8019 - sparse_categorical_accuracy: 0.0312 - top5_acc: 0.1211 - top10_acc: 0.1914 - val_loss: 10.8120 - val_sparse_categorical_accuracy: 0.0195 - val_top5_acc: 0.0547 - val_top10_acc: 0.0859\n",
      "Epoch 7/10\n",
      "256/256 [==============================] - 4s 18ms/step - loss: 10.7905 - sparse_categorical_accuracy: 0.0234 - top5_acc: 0.1445 - top10_acc: 0.2266 - val_loss: 10.8040 - val_sparse_categorical_accuracy: 0.0273 - val_top5_acc: 0.0625 - val_top10_acc: 0.0898\n",
      "Epoch 8/10\n",
      "256/256 [==============================] - 4s 16ms/step - loss: 10.7760 - sparse_categorical_accuracy: 0.0547 - top5_acc: 0.1328 - top10_acc: 0.2305 - val_loss: 10.7948 - val_sparse_categorical_accuracy: 0.0391 - val_top5_acc: 0.0625 - val_top10_acc: 0.0938\n",
      "Epoch 9/10\n",
      "256/256 [==============================] - 4s 17ms/step - loss: 10.7606 - sparse_categorical_accuracy: 0.0508 - top5_acc: 0.1484 - top10_acc: 0.2422 - val_loss: 10.7844 - val_sparse_categorical_accuracy: 0.0469 - val_top5_acc: 0.0625 - val_top10_acc: 0.1016\n",
      "Epoch 10/10\n",
      "256/256 [==============================] - 4s 17ms/step - loss: 10.7426 - sparse_categorical_accuracy: 0.0664 - top5_acc: 0.1641 - top10_acc: 0.2344 - val_loss: 10.7726 - val_sparse_categorical_accuracy: 0.0469 - val_top5_acc: 0.0625 - val_top10_acc: 0.1016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4de914a8>"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "ntrain = batch_size*1\n",
    "nval = batch_size*1\n",
    "lstm_source_model.fit([x_train_id[:ntrain], a_train[:ntrain]], y_train_id[:ntrain], \n",
    "            validation_data=([x_val_id[:nval], a_val[:ntrain]], y_val_id[:nval]),\n",
    "            epochs=10, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_source_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-579-5b9aed834e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_source_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_source_id' is not defined"
     ]
    }
   ],
   "source": [
    "x_source_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_14 (Embedding)     (None, None, 100)         5000000   \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 25)                12600     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 50000)             1300000   \n",
      "=================================================================\n",
      "Total params: 6,312,600\n",
      "Trainable params: 1,312,600\n",
      "Non-trainable params: 5,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "lstm_model = get_simple_lstm(emb, lstm_size=25)\n",
    "print(lstm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_weights(\"lstm_model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10240 samples, validate on 5120 samples\n",
      "Epoch 1/10\n",
      "10240/10240 [==============================] - 129s 13ms/step - loss: 10.0940 - sparse_categorical_accuracy: 0.0984 - val_loss: 9.8458 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 2/10\n",
      "10240/10240 [==============================] - 142s 14ms/step - loss: 9.5410 - sparse_categorical_accuracy: 0.0984 - val_loss: 9.2780 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 3/10\n",
      "10240/10240 [==============================] - 123s 12ms/step - loss: 8.9207 - sparse_categorical_accuracy: 0.0984 - val_loss: 8.7158 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 4/10\n",
      "10240/10240 [==============================] - 116s 11ms/step - loss: 8.3472 - sparse_categorical_accuracy: 0.0984 - val_loss: 8.2371 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 5/10\n",
      "10240/10240 [==============================] - 118s 12ms/step - loss: 7.8593 - sparse_categorical_accuracy: 0.0984 - val_loss: 7.8390 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 6/10\n",
      "10240/10240 [==============================] - 136s 13ms/step - loss: 7.4505 - sparse_categorical_accuracy: 0.0984 - val_loss: 7.5081 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 7/10\n",
      "10240/10240 [==============================] - 142s 14ms/step - loss: 7.1107 - sparse_categorical_accuracy: 0.0984 - val_loss: 7.2344 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 8/10\n",
      "10240/10240 [==============================] - 120s 12ms/step - loss: 6.8292 - sparse_categorical_accuracy: 0.0984 - val_loss: 7.0095 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 9/10\n",
      "10240/10240 [==============================] - 118s 12ms/step - loss: 6.5970 - sparse_categorical_accuracy: 0.0984 - val_loss: 6.8260 - val_sparse_categorical_accuracy: 0.1004\n",
      "Epoch 10/10\n",
      "10240/10240 [==============================] - 137s 13ms/step - loss: 6.4064 - sparse_categorical_accuracy: 0.0984 - val_loss: 6.6764 - val_sparse_categorical_accuracy: 0.1004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c373074a8>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelName=\"simple_lstm.hdf5\"\n",
    "checkpoint = ModelCheckpoint(modelName, monitor='val_loss', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 1024\n",
    "ntrain = batch_size*10\n",
    "nval = batch_size*5\n",
    "lstm_model.fit(x_train_id[:ntrain], y_train_id[:ntrain], \n",
    "            validation_data=(x_val_id[:nval], y_val_id[:nval]),\n",
    "            epochs=10, batch_size=batch_size,\n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The perplexity metric. Why isn't this part of Keras yet?!\n",
    "    https://stackoverflow.com/questions/41881308/how-to-calculate-perplexity-of-rnn-in-tensorflow\n",
    "    https://github.com/keras-team/keras/issues/8267\n",
    "    \"\"\"\n",
    "    cross_entropy = K.sparse_categorical_crossentropy(y_true, y_pred)\n",
    "    perplexity = K.exp(cross_entropy)\n",
    "    return perplexity\n",
    "\n",
    "top10_acc = functools.partial(keras.metrics.sparse_top_k_categorical_accuracy, k=10)\n",
    "top10_acc.__name__ = 'top10_acc'\n",
    "\n",
    "def simple_attention_model(embeddings):\n",
    "    vocab_size, word_embedding_dim=embeddings.shape \n",
    "    word_sequence_input = Input(shape=(None,), dtype='int32')\n",
    "    \n",
    "    word_embedding_layer = Embedding(vocab_size,\n",
    "                                    word_embedding_dim,\n",
    "                                    weights=[embeddings],\n",
    "                                    trainable=False)\n",
    "\n",
    "    \n",
    "    # input - embeddings\n",
    "    embedded_sequences = word_embedding_layer(word_sequence_input)\n",
    "    \n",
    "    # reduce embedding dimensionality\n",
    "    attention_key_dim=25\n",
    "    attention_input=Dense(attention_key_dim, activation='tanh')(embedded_sequences)\n",
    "    \n",
    "    attention_output = AttentionLayerMasking(word_embedding_dim, name=\"attention\")(attention_input)\n",
    "    \n",
    "    # now let's multiply those attention weights by original inputs to get a weighted average over them\n",
    "    document_representation = Lambda(lambda x: K.batch_dot(x[0], x[1], axes=1), \n",
    "                                     name='dot')([attention_output,attention_input])\n",
    "    \n",
    "    x=Dense(vocab_size, activation=\"softmax\")(document_representation)\n",
    "    \n",
    "    model = Model(inputs=word_sequence_input, outputs=x)\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['sparse_categorical_accuracy', top10_acc, perplexity])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_13 (Embedding)        (None, None, 100)    5000000     input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, None, 25)     2525        embedding_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "attention (AttentionLayerMaskin (None, None)         25          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot (Lambda)                    (None, 25)           0           attention[0][0]                  \n",
      "                                                                 dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 50000)        1300000     dot[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 6,302,550\n",
      "Trainable params: 1,302,550\n",
      "Non-trainable params: 5,000,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "attn_model = simple_attention_model(emb)\n",
    "print(attn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5120 samples, validate on 1280 samples\n",
      "Epoch 1/10\n",
      "5120/5120 [==============================] - 68s 13ms/step - loss: 10.6819 - sparse_categorical_accuracy: 0.0498 - top10_acc: 0.1650 - perplexity: 44005.7113 - val_loss: 10.4469 - val_sparse_categorical_accuracy: 0.0992 - val_top10_acc: 0.2508 - val_perplexity: 35184.6352\n",
      "Epoch 2/10\n",
      "3328/5120 [==================>...........] - ETA: 55s - loss: 10.1788 - sparse_categorical_accuracy: 0.1013 - top10_acc: 0.2981 - perplexity: 27255.1047 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-d49639aecbf2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnval\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/DMA/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/DMA/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DMA/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DMA/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DMA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelName=\"simple_attn_lstm.hdf5\"\n",
    "checkpoint = ModelCheckpoint(modelName, monitor='val_perplexity', verbose=0, save_best_only=True, mode='min')\n",
    "\n",
    "batch_size = 256\n",
    "ntrain = batch_size*20\n",
    "nval = batch_size*5\n",
    "attn_model.fit(x_train_id[:ntrain], y_train_id[:ntrain], \n",
    "            validation_data=(x_val_id[:nval], y_val_id[:nval]),\n",
    "            epochs=10, batch_size=batch_size,\n",
    "            callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# domain_emb = []\n",
    "# for i in range (1000):\n",
    "#     domain_emb.append(np.zeros(emb.shape[1]))\n",
    "    \n",
    "# emb = np.concatenate((emb, np.array(domain_emb)))\n",
    "\n",
    "# lstm_model = get_simple_lstm(emb, lstm_size=100)\n",
    "lstm_model.load_weights(\"lstm100/lstm100_best_ppx.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> good night\n",
      "\n",
      "good night \n",
      "( come from the life of god ) the fucking face \n",
      "'cause it 's go , where you wo n't no rap and go \n",
      "\n",
      "i 'm gonna change to just \n",
      "i take you to my head from the track \n",
      "i got my a life in the top \n",
      "my girl and do n't stop real \n",
      "so i just take it \n",
      "from my time to death , you can be where your heart we want ? ) \n",
      "we made it \n",
      "i seen on you up a nigga \n",
      "never should rather "
     ]
    }
   ],
   "source": [
    "id2tok = {v:k for k,v in tok2id.items()}\n",
    "def sample_vocab_topk(probs, k=10):\n",
    "    \n",
    "    # the token at index 1 is <UNK>\n",
    "    # remove it since it will be the most probably token all the time\n",
    "    probs = np.delete(probs, 1)\n",
    "    \n",
    "    idx = np.argsort(probs) # sorts in ascending oder\n",
    "    probs = probs[idx[-k:]] # look at top k most probable predictions\n",
    "    probs /= sum(probs) # normalize so probabilities sum up to 1\n",
    "    \n",
    "    sample = np.random.choice(idx[-k:], p=probs)\n",
    "    return sample+1 if sample>0 else 0 # adjust because removed idx 1 above\n",
    "\n",
    "#     return np.random.choice(idx[-k:], p=probs) # sample from top k predictions\n",
    "\n",
    "def sample_vocab(probs):\n",
    "    return np.random.choice(np.arange(len(probs)), p=probs)\n",
    "\n",
    "def predict_batch(model, seed):\n",
    "#     n = 100\n",
    "#     seed = np.array(x_val_id[100:100+n])\n",
    "    n = len(seed)\n",
    "    yhat = model.predict_on_batch(seed)\n",
    "    predictions = [sample_vocab(row) for row in yhat]\n",
    "    for i in range(n):\n",
    "        print([id2tok[j] for j in seed[i]], id2tok[predictions[i]])\n",
    "\n",
    "def generate(model, seed, n):\n",
    "\n",
    "#     seed = x_train_id[4000]\n",
    "    # seedStr = '<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> show me where '\n",
    "    # seed = [tok2id[w] for w in seedStr.split()]\n",
    "    # seed = [0,0,0,0,0,0,0,0,0]\n",
    "    l = len(seed)\n",
    "    # print([id2tok[j] for j in seed])\n",
    "    s = ' '.join([id2tok[j] for j in seed])\n",
    "    print(s)\n",
    "    for i in range(n):\n",
    "        seed1 = seed[-l:]\n",
    "#         print(' '.join([id2tok[j] for j in seed1]))\n",
    "        \n",
    "        pred = lstm_model.predict(np.array([seed1]))\n",
    "        \n",
    "#         next_tok = sample_vocab(pred[0])\n",
    "        next_tok = sample_vocab_topk(pred[0], 100)\n",
    "        \n",
    "        \n",
    "        tok = id2tok[next_tok]\n",
    "        if tok == '<PAD>':\n",
    "            break\n",
    "        s += ' ' + tok\n",
    "        seed.append(next_tok)\n",
    "\n",
    "    print()\n",
    "    for tok in s.split():\n",
    "        if tok=='<PAD>':\n",
    "            continue\n",
    "        elif tok=='<BR>':\n",
    "            print()\n",
    "        else:\n",
    "            print(tok, end=' ')\n",
    "\n",
    "seed = \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> good night\"\n",
    "seed = [tok2id[t] for t in seed.split()]\n",
    "# generate(lstm_model, list(x_train_id[500]), 200) \n",
    "generate(lstm_model, seed, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124.78662014007568\n",
      "262672.1653450545\n",
      "122.75528049468994\n",
      "214384.85130782082\n"
     ]
    }
   ],
   "source": [
    "def sparse_cross_ent(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    cross_ent = 0\n",
    "    for i in range(n):\n",
    "        cross_ent -= np.log(y_pred[i][y_true[i]])\n",
    "    return cross_ent/n, np.exp(cross_ent/n)\n",
    "    \n",
    "        \n",
    "def perplexity_check(model, test_x, test_y):\n",
    "    yhat = model.predict_on_batch(seed)\n",
    "    n = len(yhat)\n",
    "    \n",
    "    neg_log_prob = 0\n",
    "    for i in range(n):\n",
    "        neg_log_prob -= np.log(yhat[i][test_y[i]])\n",
    "#         neg_log_prob -= yhat[i][test_y[i]]\n",
    "    print(neg_log_prob)\n",
    "    return np.exp(neg_log_prob/n)\n",
    "    \n",
    "    \n",
    "print(perplexity_check(lstm_model, np.array(x_val_id), np.array(y_val_id)))\n",
    "print(perplexity_check(lstm_model, np.array(x_train_id), np.array(y_train_id)))\n",
    "\n",
    "# predict_batch(lstm_model, np.array(x_val_id[100:110]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.941591503880918, 139.99287155951305)"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sparse_cross_ent(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    cross_ent = 0\n",
    "    for i in range(n):\n",
    "        cross_ent -= np.log(y_pred[i][y_true[i]])\n",
    "    return cross_ent/n, np.exp(cross_ent/n)\n",
    "\n",
    "y_pred = lstm_model.predict_on_batch(x_val_id[:200])\n",
    "sparse_cross_ent(y_val_id[:200], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 2s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.4862969144185385,\n",
       " 0.24666666686534883,\n",
       " 0.4633333333333333,\n",
       " 0.5566666674613953,\n",
       " 393326.2157340495]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model.evaluate(x_train_id[:300], y_train_id[:300], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30816.334"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(K.exp(10.3358))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.7254613557728"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(4.5188)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DMA] *",
   "language": "python",
   "name": "conda-env-DMA-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
